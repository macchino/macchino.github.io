{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokyo_yakitori_review",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOGEFA6yWudcV6AYWjwd8+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/macchino/macchino.github.io/blob/master/Tokyo_yakitori_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjXUQxUDf2Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install MeCab\n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n",
        "!pip install -U mecab-python3 > /dev/null\n",
        "#!pip install unidic-lite\n",
        "#!pip install ipadic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhsMNKH-lucB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check path to \"ipadic-neologd\" \n",
        "!echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxHFB0EV9m1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from gensim.models import word2vec\n",
        "import MeCab\n",
        "\n",
        "tagger = MeCab.Tagger('-Owakati -r /dev/null -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
        "\n",
        "tagger.parse('')\n",
        "def tokenize_ja(text, lower):\n",
        "    node = tagger.parseToNode(str(text))\n",
        "    while node:\n",
        "        if lower and node.feature.split(',')[0] in [\"名詞\",\"形容詞\"]:#分かち書きで取得する品詞を指定\n",
        "            yield node.surface.lower()\n",
        "        node = node.next\n",
        "def tokenize(content, token_min_len, token_max_len, lower):\n",
        "    return [\n",
        "        str(token) for token in tokenize_ja(content, lower)\n",
        "        if token_min_len <= len(token) <= token_max_len and not token.startswith('_')\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "#学習データの読み込み\n",
        "\n",
        "df = pd.read_csv('tokyo_yaktori_review.csv')\n",
        "df_yaktori = df.groupby(['store_name','score','review_cnt'])['review'].apply(list).apply(' '.join).reset_index().sort_values('score', ascending=False)\n",
        "\n",
        "#コーパス作成\n",
        "wakati_yaktori_text = []\n",
        "for i in df_yaktori['review']:\n",
        "    txt = tokenize(i, 2, 10000, True)\n",
        "    wakati_yaktori_text.append(txt)\n",
        "#↓↓↓↓↓↓↓ あなたの記事の内容\n",
        "np.savetxt(\"yaktori_corpus.txt\", wakati_yaktori_text,fmt='%s', delimiter=',')\n",
        "#───────\n",
        "np.savetxt(\"yaktori_corpus.txt\", wakati_yaktori_text, fmt = '%s', delimiter = ',')\n",
        "#↑↑↑↑↑↑↑ 編集リクエストの内容\n",
        "# モデル作成\n",
        "#↓↓↓↓↓↓↓ あなたの記事の内容\n",
        "word2vec_yaktori_model = word2vec.Word2Vec(wakati_yaktori_text,sg=1,size=100, window=5,min_count=5,iter=100,workers=3)\n",
        "#───────\n",
        "word2vec_ramen_model = word2vec.Word2Vec(wakati_yaktori_text, sg = 1, size = 100, window = 5, min_count = 5, iter = 100, workers = 3)\n",
        "#↑↑↑↑↑↑↑ 編集リクエストの内容\n",
        "#sg（0: CBOW, 1: skip-gram）,size（ベクトルの次元数）,window（学習に使う前後の単語数）,min_count（n回未満登場する単語を破棄）,iter（トレーニング反復回数）\n",
        "\n",
        "# モデルのセーブ\n",
        "word2vec_yaktori_model.save(\"word2vec_yaktori_model.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UntyliS5YR7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルのロード\n",
        "word2vec_yaktori_model =word2vec.Word2Vec.load(\"word2vec_yaktori_model.model\")\n",
        "word2vec_yaktori_model.most_similar(\"海鮮\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk8VWqeQbE0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#足し算\n",
        "word2vec_yaktori_model.most_similar(positive=[u\"銀座\",u\"焼鳥\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v97Iju0QcCN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#引き算\n",
        "word2vec_yaktori_model.most_similar(positive=[u\"焼鳥\",u\"炭火\"], negative=[u\"銀座\"])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}